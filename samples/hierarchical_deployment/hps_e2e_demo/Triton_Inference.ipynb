{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a327cb",
   "metadata": {},
   "source": [
    "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# HugeCTR Continuous Training and Inference Demo (Part II)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8e27d7",
   "metadata": {},
   "source": [
    "## Inference using Triton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8efc81c",
   "metadata": {},
   "source": [
    "### 1.1 Generate related model folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc8da341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "import re\n",
    "import shutil\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "BASE_DIR = \"/wdl_infer\"\n",
    "model_folder  = os.path.join(BASE_DIR, \"model\")\n",
    "wdl_model_repo= os.path.join(model_folder, \"wdl\")\n",
    "wdl_version =os.path.join(wdl_model_repo, \"1\")\n",
    "\n",
    "if os.path.isdir(model_folder):\n",
    "    shutil.rmtree(model_folder)\n",
    "os.makedirs(model_folder)\n",
    "\n",
    "if os.path.isdir(wdl_model_repo):\n",
    "    shutil.rmtree(wdl_model_repo)\n",
    "os.makedirs(wdl_model_repo)\n",
    "\n",
    "if os.path.isdir(wdl_version):\n",
    "    shutil.rmtree(wdl_version)\n",
    "os.makedirs(wdl_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72680473",
   "metadata": {},
   "source": [
    "### 1.2 Copy WDL model files and configuration to model repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8395d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5840\n",
      "-rw-r--r-- 1 root root    3628 Dec  3 03:36 wdl.json\n",
      "drwxr-xr-x 2 root root    4096 Dec  3 03:36 wdl_0_sparse_model\n",
      "drwxr-xr-x 2 root root    4096 Dec  3 03:36 wdl_1_sparse_model\n",
      "-rw-r--r-- 1 root root 5963780 Dec  3 03:36 wdl_dense_0.model\n"
     ]
    }
   ],
   "source": [
    "!cp -r wdl_0_sparse_model $wdl_version/\n",
    "!cp -r wdl_1_sparse_model $wdl_version/\n",
    "!cp  wdl_dense_0.model $wdl_version/\n",
    "!cp wdl.json $wdl_version/\n",
    "!ls -l $wdl_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf12406f",
   "metadata": {},
   "source": [
    "### 1.3 Generate the Triton configuration for deploying WDL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16a4b767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /wdl_infer/model/wdl/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $wdl_model_repo/config.pbtxt\n",
    "name: \"wdl\"\n",
    "backend: \"hugectr\"\n",
    "max_batch_size:64,\n",
    "input [\n",
    "   {\n",
    "    name: \"DES\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ -1 ]\n",
    "  },\n",
    "  {\n",
    "    name: \"CATCOLUMN\"\n",
    "    data_type: TYPE_INT64\n",
    "    dims: [ -1 ]\n",
    "  },\n",
    "  {\n",
    "    name: \"ROWINDEX\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [ -1 ]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"OUTPUT0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ -1 ]\n",
    "  }\n",
    "]\n",
    "instance_group [\n",
    "  {\n",
    "    count: 1\n",
    "    kind : KIND_GPU\n",
    "    gpus:[0]\n",
    "  }\n",
    "]\n",
    "\n",
    "parameters [\n",
    "  {\n",
    "  key: \"config\"\n",
    "  value: { string_value: \"/wdl_infer/model/wdl/1/wdl.json\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"gpucache\"\n",
    "  value: { string_value: \"true\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"hit_rate_threshold\"\n",
    "  value: { string_value: \"0.8\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"refresh_interval\"\n",
    "  value: { string_value: \"20\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"refresh_delay\"\n",
    "  value: { string_value: \"0.0\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"gpucacheper\"\n",
    "  value: { string_value: \"0.5\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"label_dim\"\n",
    "  value: { string_value: \"1\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"slots\"\n",
    "  value: { string_value: \"27\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"cat_feature_num\"\n",
    "  value: { string_value: \"28\" }\n",
    "  },\n",
    " {\n",
    "  key: \"des_feature_num\"\n",
    "  value: { string_value: \"13\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"max_nnz\"\n",
    "  value: { string_value: \"2\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"embedding_vector_size\"\n",
    "  value: { string_value: \"16\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"embeddingkey_long_type\"\n",
    "  value: { string_value: \"true\" }\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adc54cc",
   "metadata": {},
   "source": [
    "### 1.4 Make a directory for RocksDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa7c3c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/wdl_infer/rocksdb’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir /wdl_infer/rocksdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7384a6",
   "metadata": {},
   "source": [
    "### 1.5 Generate the HugeCTR Backend parameter server configuration for deploying WDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0fb4a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /wdl_infer/model/ps.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile /wdl_infer/model/ps.json\n",
    "{\n",
    "    \"supportlonglong\":true,\n",
    "    \"cpu_memory_db\": {\n",
    "        \"type\": \"disabled\",\n",
    "        \"num_partitions\": 8,\n",
    "        \"overflow_policy\": \"evict_oldest\",\n",
    "        \"overflow_margin\": 1000000,\n",
    "        \"overflow_resolution_target\": 0.8,\n",
    "        \"initial_cache_rate\": 0.2,\n",
    "        \"update_filters\": [ \"wurst0\", \".+\" ]\n",
    "    },\n",
    "    \"distributed_db\": {\n",
    "        \"type\": \"redis_cluster\",\n",
    "        \"address\": \"127.0.0.1:7003,127.0.0.1:7004,127.0.0.1:7005\",\n",
    "        \"user_name\": \"default\",\n",
    "        \"password\": \"\",\n",
    "        \"num_partitions\": 8,\n",
    "        \"max_get_batch_size\": 100000,\n",
    "        \"max_set_batch_size\": 100000,\n",
    "        \"overflow_policy\": \"evict_oldest\",\n",
    "        \"overflow_margin\": 10000000,\n",
    "        \"overflow_resolution_target\": 0.8,\n",
    "        \"initial_cache_rate\": 1.0,\n",
    "        \"update_filters\": [ \"wurst1\", \".+\" ]\n",
    "    },\n",
    "    \"persistent_db\": {\n",
    "        \"type\": \"rocksdb\",\n",
    "        \"path\": \"/wdl_infer/rocksdb\",\n",
    "        \"num_threads\": 16,\n",
    "        \"read_only\": false,\n",
    "        \"max_get_batch_size\": 1,\n",
    "        \"max_set_batch_size\": 10000,\n",
    "        \"update_filters\": [ \"wurst2\", \".+\" ]\n",
    "    },\n",
    "    \"update_source\": {\n",
    "        \"type\": \"kafka\",\n",
    "        \"brokers\": \"10.23.137.25:9093\",\n",
    "        \"poll_timeout_ms\": 500,\n",
    "        \"max_receive_buffer_size\": 2000,\n",
    "        \"max_batch_size\": 1000,\n",
    "        \"failure_backoff_ms\": 50\n",
    "    },\n",
    "    \"models\":[\n",
    "        {\n",
    "            \"model\":\"wdl\",\n",
    "            \"sparse_files\":[\"/wdl_infer/model/wdl/1/wdl_0_sparse_model\", \"/wdl_infer/model/wdl/1/wdl_1_sparse_model\"],\n",
    "            \"dense_file\":\"/wdl_infer/model/wdl/1/wdl_dense_0.model\",\n",
    "            \"network_file\":\"/wdl_infer/model/wdl/1/wdl.json\",\n",
    "            \"num_of_worker_buffer_in_pool\": \"1\",\n",
    "            \"num_of_refresher_buffer_in_pool\": \"1\",\n",
    "            \"cache_refresh_percentage_per_iteration\": \"0.2\",\n",
    "            \"deployed_device_list\":[\"0\"],\n",
    "            \"max_batch_size\":\"64\",\n",
    "            \"default_value_for_each_table\":[\"0.0\",\"0.0\"],\n",
    "            \"hit_rate_threshold\":\"0.9\",\n",
    "            \"gpucacheper\":\"0.5\",\n",
    "            \"gpucache\":\"true\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e94cc07",
   "metadata": {},
   "source": [
    "### 2.1 Start Triton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b11b5a",
   "metadata": {},
   "source": [
    "**Please make sure you have started Redis cluster following the README before you start Triton.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6027f331",
   "metadata": {},
   "source": [
    "**Start the Triton server in a new terminal using the following command:**\n",
    "```\n",
    "tritonserver --model-repository=/wdl_infer/model/ --load-model=wdl --model-control-mode=explicit --backend-directory=/usr/local/hugectr/backends --backend-config=hugectr,ps=/wdl_infer/model/ps.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a397bd",
   "metadata": {},
   "source": [
    "### 2.2 Inference using Triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd616aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting triton_infer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile triton_infer.py\n",
    "\n",
    "from tritonclient.utils import *\n",
    "import tritonclient.http  as httpclient\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "model_name = 'wdl'\n",
    "CATEGORICAL_COLUMNS=[\"C1_C2\",\"C3_C4\"] + [\"C\" + str(x) for x in range(1, 27)]\n",
    "CONTINUOUS_COLUMNS=[\"I\" + str(x) for x in range(1, 14)]\n",
    "LABEL_COLUMNS = ['label']\n",
    "test_df=pd.read_csv(\"infer_data.csv\",sep=',')\n",
    "\n",
    "with httpclient.InferenceServerClient(\"localhost:8000\") as client:\n",
    "    dense_features = np.array([list(test_df[CONTINUOUS_COLUMNS].values.flatten())],dtype='float32')\n",
    "    embedding_columns = np.array([list((test_df[CATEGORICAL_COLUMNS]).values.flatten())],dtype='int64')\n",
    "    row_ptrs = np.array([list(range(0,11, 2)) + list(range(0,131))], dtype='int32')\n",
    "    \n",
    "    inputs = [\n",
    "        httpclient.InferInput(\"DES\", dense_features.shape,\n",
    "                              np_to_triton_dtype(dense_features.dtype)),\n",
    "        httpclient.InferInput(\"CATCOLUMN\", embedding_columns.shape,\n",
    "                              np_to_triton_dtype(embedding_columns.dtype)),\n",
    "        httpclient.InferInput(\"ROWINDEX\", row_ptrs.shape,\n",
    "                              np_to_triton_dtype(row_ptrs.dtype)),\n",
    "\n",
    "    ]\n",
    "\n",
    "    inputs[0].set_data_from_numpy(dense_features)\n",
    "    inputs[1].set_data_from_numpy(embedding_columns)\n",
    "    inputs[2].set_data_from_numpy(row_ptrs)\n",
    "    outputs = [\n",
    "        httpclient.InferRequestedOutput(\"OUTPUT0\")\n",
    "    ]\n",
    "\n",
    "    response = client.infer(model_name,\n",
    "                            inputs,\n",
    "                            request_id=str(1),\n",
    "                            outputs=outputs)\n",
    "\n",
    "    result = response.get_response()\n",
    "    print(result)\n",
    "    print(\"Prediction Result:\")\n",
    "    print(response.as_numpy(\"OUTPUT0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62848c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '1', 'model_name': 'wdl', 'model_version': '1', 'parameters': {'NumSample': 5, 'DeviceID': 0}, 'outputs': [{'name': 'OUTPUT0', 'datatype': 'FP32', 'shape': [5], 'parameters': {'binary_data_size': 20}}]}\n",
      "Prediction Result:\n",
      "[0.01366859 0.00814866 0.06785329 0.00727612 0.01993068]\n"
     ]
    }
   ],
   "source": [
    "!python3 triton_infer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42195fa5",
   "metadata": {},
   "source": [
    "### 2.3 Continuous inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49211bb",
   "metadata": {},
   "source": [
    "**Send inference request again after [continous training](./Continuous_Training.ipynb) was done:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62f374b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '1', 'model_name': 'wdl', 'model_version': '1', 'parameters': {'NumSample': 5, 'DeviceID': 0}, 'outputs': [{'name': 'OUTPUT0', 'datatype': 'FP32', 'shape': [5], 'parameters': {'binary_data_size': 20}}]}\n",
      "Prediction Result:\n",
      "[0.00362184 0.00090019 0.05462332 0.00286225 0.00531276]\n"
     ]
    }
   ],
   "source": [
    "!python3 triton_infer.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
