{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we want to provide a tutorial about how to make inference using HugeCTR trained WDL model. And we can collect the inference benchmark by Triton performance analyzer tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Overview\n",
    "2. Generate the WDL deployment Configuration\n",
    "3. Load Models on the Triton Server\n",
    "4. Prepare Inference Input Data \n",
    "5. Inference Benchmarm by Triton Performance Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generate the WDL Deployment Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Generate related model folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some data folder to store the model related files\n",
    "# Standard Libraries\n",
    "import os\n",
    "from time import time\n",
    "import re\n",
    "import shutil\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "BASE_DIR = \"/wdl_infer\"\n",
    "model_folder  = os.path.join(BASE_DIR, \"model\")\n",
    "wdl_model_repo= os.path.join(model_folder, \"wdl\")\n",
    "wdl_version =os.path.join(wdl_model_repo, \"1\")\n",
    "\n",
    "if os.path.isdir(model_folder):\n",
    "    shutil.rmtree(model_folder)\n",
    "os.makedirs(model_folder)\n",
    "\n",
    "if os.path.isdir(wdl_model_repo):\n",
    "    shutil.rmtree(wdl_model_repo)\n",
    "os.makedirs(wdl_model_repo)\n",
    "\n",
    "if os.path.isdir(wdl_version):\n",
    "    shutil.rmtree(wdl_version)\n",
    "os.makedirs(wdl_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Copy WDL model files and configuration to model repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5840\r\n",
      "-rw-r--r-- 1 root root    3158 Jul  6 07:17 wdl.json\r\n",
      "drwxr-xr-x 2 root root    4096 Jul  6 07:17 wdl0_sparse_20000.model\r\n",
      "drwxr-xr-x 2 root root    4096 Jul  6 07:17 wdl1_sparse_20000.model\r\n",
      "-rw-r--r-- 1 root root 5963780 Jul  6 07:17 wdl_dense_20000.model\r\n"
     ]
    }
   ],
   "source": [
    "!cp -r /wdl_train/wdl0_sparse_20000.model $wdl_version/\n",
    "!cp -r /wdl_train/wdl1_sparse_20000.model $wdl_version/\n",
    "!cp  /wdl_train/wdl_dense_20000.model $wdl_version/\n",
    "!cp /wdl_train/wdl.json $wdl_version/\n",
    "!ls -l $wdl_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Generate the Triton configuration for deploying WDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /wdl_infer/model/wdl/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $wdl_model_repo/config.pbtxt\n",
    "name: \"wdl\"\n",
    "backend: \"hugectr\"\n",
    "max_batch_size:64,\n",
    "input [\n",
    "   {\n",
    "    name: \"DES\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ -1 ]\n",
    "  },\n",
    "  {\n",
    "    name: \"CATCOLUMN\"\n",
    "    data_type: TYPE_INT64\n",
    "    dims: [ -1 ]\n",
    "  },\n",
    "  {\n",
    "    name: \"ROWINDEX\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [ -1 ]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"OUTPUT0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ -1 ]\n",
    "  }\n",
    "]\n",
    "instance_group [\n",
    "  {\n",
    "    count: 1\n",
    "    kind : KIND_GPU\n",
    "    gpus:[0]\n",
    "  }\n",
    "]\n",
    "\n",
    "parameters [\n",
    "  {\n",
    "  key: \"config\"\n",
    "  value: { string_value: \"/wdl_infer/model/wdl/1/wdl.json\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"gpucache\"\n",
    "  value: { string_value: \"true\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"hit_rate_threshold\"\n",
    "  value: { string_value: \"0.8\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"gpucacheper\"\n",
    "  value: { string_value: \"0.5\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"label_dim\"\n",
    "  value: { string_value: \"1\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"slots\"\n",
    "  value: { string_value: \"28\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"cat_feature_num\"\n",
    "  value: { string_value: \"28\" }\n",
    "  },\n",
    " {\n",
    "  key: \"des_feature_num\"\n",
    "  value: { string_value: \"13\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"max_nnz\"\n",
    "  value: { string_value: \"2\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"embedding_vector_size\"\n",
    "  value: { string_value: \"128\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"embeddingkey_long_type\"\n",
    "  value: { string_value: \"true\" }\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 configure a RocksDB directory for localized storage\n",
    "Make sure the RocksDB directory has read and write permissions for storing model embedded tables. Since we have created the RocksDB folder outside the container, please make sure to mount the correct folder path to /wdl_infer/rocksdb and configure the correct RocksDB path to the ps.json in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Generate the Hugectr Backend parameter server configuration for deploying wdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /wdl_infer/model/ps.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile /wdl_infer/model/ps.json\n",
    "{\n",
    "    \"supportlonglong\":true,\n",
    "    \"db_type\":\"hierarchy\",\n",
    "    \"redis_ip\":\"127.0.0.1:7000,127.0.0.1:7001,127.0.0.1:7002\",\n",
    "    \"rocksdb_path\":\"/wdl_infer/rocksdb\",\n",
    "    \"cache_size_percentage_redis\":\"0.1\",\n",
    "    \"models\":[\n",
    "        {\n",
    "            \"model\":\"wdl\",\n",
    "            \"sparse_files\":[\"/wdl_infer/model/wdl/1/wdl0_sparse_20000.model\", \"/wdl_infer/model/wdl/1/wdl1_sparse_20000.model\"],\n",
    "            \"dense_file\":\"/wdl_infer/model/wdl/1/wdl_dense_20000.model\",\n",
    "            \"network_file\":\"/wdl_infer/model/wdl/1/wdl.json\",\n",
    "            \"num_of_worker_buffer_in_pool\": \"4\",\n",
    "\t\t\t\"deployed_device_list\":[\"0\"],\n",
    "\t\t\t\"max_batch_size\":\"1024\",\n",
    "\t\t\t\"default_value_for_each_table\":[\"0.0\",\"0.0\"],\n",
    "            \"hit_rate_threshold\":\"0.9\",\n",
    "            \"gpucacheper\":\"0.5\",\n",
    "            \"gpucache\":\"true\"\n",
    "\n",
    "        }\n",
    "    ]  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\n",
      "drwxr-xr-x 4 root root 4096 Jul  6 07:16 1\n",
      "-rw-r--r-- 1 root root 1174 Jul  6 07:17 config.pbtxt\n",
      "total 5840\n",
      "-rwxrwxrwx 1 root root    3590 Jul 29 07:49 wdl.json\n",
      "drwxr-xr-x 2 root root    4096 Jul  6 07:17 wdl0_sparse_20000.model\n",
      "drwxr-xr-x 2 root root    4096 Jul  6 07:17 wdl1_sparse_20000.model\n",
      "-rw-r--r-- 1 root root 5963780 Jul  6 07:17 wdl_dense_20000.model\n"
     ]
    }
   ],
   "source": [
    "!ls  -l $wdl_model_repo\n",
    "!ls -l $wdl_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Deploy WDL on Triton Server "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, you should have already launched the Triton Inference Server with the following command:\n",
    "\n",
    "In this tutorial, we will deploy the Wide&Deep to a single A100(32GB),\n",
    "\n",
    "`Since Background processes not supported by Jupyter, please launch the triton server according to the following command independently`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tritonserver: /opt/conda/lib/libcurl.so.4: no version information available (required by /opt/tritonserver/bin/../lib/libtritonserver.so)\n",
      "I0914 10:45:56.023240 2543 metrics.cc:228] Collecting metrics for GPU 0: NVIDIA A100-PCIE-40GB\n",
      "I0914 10:45:56.037039 2543 metrics.cc:228] Collecting metrics for GPU 1: NVIDIA A10\n",
      "I0914 10:45:56.049695 2543 metrics.cc:228] Collecting metrics for GPU 2: NVIDIA A30\n",
      "I0914 10:45:56.061967 2543 metrics.cc:228] Collecting metrics for GPU 3: Tesla T4\n",
      "I0914 10:45:56.664522 2543 pinned_memory_manager.cc:206] Pinned memory pool is created at '0x7f904e000000' with size 268435456\n",
      "I0914 10:45:56.685953 2543 cuda_memory_manager.cc:103] CUDA memory pool is created on device 0 with size 67108864\n",
      "I0914 10:45:56.685989 2543 cuda_memory_manager.cc:103] CUDA memory pool is created on device 1 with size 67108864\n",
      "I0914 10:45:56.686009 2543 cuda_memory_manager.cc:103] CUDA memory pool is created on device 2 with size 67108864\n",
      "I0914 10:45:56.686027 2543 cuda_memory_manager.cc:103] CUDA memory pool is created on device 3 with size 67108864\n",
      "W0914 10:45:57.804237 2543 server.cc:189] failed to enable peer access for some device pairs\n",
      "I0914 10:45:58.202443 2543 model_repository_manager.cc:1066] loading: wdl:1\n",
      "I0914 10:45:58.418224 2543 hugectr.cc:1021] TRITONBACKEND_Initialize: hugectr\n",
      "I0914 10:45:58.418285 2543 hugectr.cc:1031] Triton TRITONBACKEND API version: 1.0\n",
      "I0914 10:45:58.418307 2543 hugectr.cc:1037] 'hugectr' TRITONBACKEND API version: 1.0\n",
      "I0914 10:45:58.418328 2543 hugectr.cc:1062] The HugeCTR backend Repository location: /usr/local/hugectr/backends/hugectr\n",
      "I0914 10:45:58.418348 2543 hugectr.cc:1072] The HugeCTR backend configuration:\n",
      "{\"cmdline\":{\"ps\":\"/wdl_infer/model/ps.json\"}}\n",
      "I0914 10:45:58.418442 2543 hugectr.cc:280] *****Parsing Parameter Server Configuration from /wdl_infer/model/ps.json\n",
      "I0914 10:45:58.418513 2543 hugectr.cc:294] Enable support for Int64 embedding key: 1\n",
      "I0914 10:45:58.418534 2543 hugectr.cc:298] The depolyment Data base type is: hierarchy\n",
      "I0914 10:45:58.418556 2543 hugectr.cc:304] The depolyment cache_size_percentage_redis is: 0.01\n",
      "I0914 10:45:58.418576 2543 hugectr.cc:308] Redis ip is: 127.0.0.1:7000,127.0.0.1:7001,127.0.0.1:7002\n",
      "I0914 10:45:58.418595 2543 hugectr.cc:312] Local RocksDB path is: /wdl_infer/rocksdb\n",
      "I0914 10:45:58.418615 2543 hugectr.cc:323] The model name is: wdl\n",
      "I0914 10:45:58.418634 2543 hugectr.cc:326] The model dense file path is: /wdl_infer/model/wdl/1/wdl_dense_20000.model\n",
      "I0914 10:45:58.418654 2543 hugectr.cc:331] The model network file path is: /wdl_infer/model/wdl/1/wdl.json\n",
      "I0914 10:45:58.418682 2543 hugectr.cc:364] *****The HugeCTR Backend Parameter Server is creating...*****\n",
      "I0914 10:45:58.418715 2543 hugectr.cc:372] ***** Parameter Server(Int64) is creating...***** \n",
      "[14d10h45m58s][HUGECTR][INFO]: default_emb_vec_value is not specified using default: 0.000000\n",
      "[14d10h45m58s][HUGECTR][INFO]: default_emb_vec_value is not specified using default: 0.000000\n",
      "Reidis Cluster is initializing the embedding table: wdl0\n",
      "Last Iteration insert successfully\n",
      "Local RocksDB is initializing the embedding table: wdl0\n",
      "Last Iteration insert successfully\n",
      "[DEBUG]/triton/hugectr/HugeCTR/src/inference/hierarchicaldb.cpp|mset|LINE121 Set key to Redis and RocksDB successfully\n",
      "Reidis Cluster is initializing the embedding table: wdl1\n",
      "Last Iteration insert successfully\n",
      "Local RocksDB is initializing the embedding table: wdl1\n",
      "Last Iteration insert successfully\n",
      "[DEBUG]/triton/hugectr/HugeCTR/src/inference/hierarchicaldb.cpp|mset|LINE121 Set key to Redis and RocksDB successfully\n",
      "I0914 10:46:05.779474 2543 hugectr.cc:380] *****The HugeCTR Backend Backend created the Parameter Server successfully!*****\n",
      "I0914 10:46:05.867702 2543 hugectr.cc:1141] TRITONBACKEND_ModelInitialize: wdl (version 1)\n",
      "I0914 10:46:05.867745 2543 hugectr.cc:1156] Repository location: /wdl_infer/model/wdl\n",
      "I0914 10:46:05.867776 2543 hugectr.cc:1173] backend configuration in mode:\n",
      "{\"cmdline\":{\"ps\":\"/wdl_infer/model/ps.json\"}}\n",
      "I0914 10:46:05.870561 2543 hugectr.cc:566] Verifying model configuration:\n",
      "{\n",
      "    \"name\": \"wdl\",\n",
      "    \"platform\": \"\",\n",
      "    \"backend\": \"hugectr\",\n",
      "    \"version_policy\": {\n",
      "        \"latest\": {\n",
      "            \"num_versions\": 1\n",
      "        }\n",
      "    },\n",
      "    \"max_batch_size\": 64,\n",
      "    \"input\": [\n",
      "        {\n",
      "            \"name\": \"DES\",\n",
      "            \"data_type\": \"TYPE_FP32\",\n",
      "            \"format\": \"FORMAT_NONE\",\n",
      "            \"dims\": [\n",
      "                -1\n",
      "            ],\n",
      "            \"is_shape_tensor\": false,\n",
      "            \"allow_ragged_batch\": false\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"CATCOLUMN\",\n",
      "            \"data_type\": \"TYPE_INT64\",\n",
      "            \"format\": \"FORMAT_NONE\",\n",
      "            \"dims\": [\n",
      "                -1\n",
      "            ],\n",
      "            \"is_shape_tensor\": false,\n",
      "            \"allow_ragged_batch\": false\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"ROWINDEX\",\n",
      "            \"data_type\": \"TYPE_INT32\",\n",
      "            \"format\": \"FORMAT_NONE\",\n",
      "            \"dims\": [\n",
      "                -1\n",
      "            ],\n",
      "            \"is_shape_tensor\": false,\n",
      "            \"allow_ragged_batch\": false\n",
      "        }\n",
      "    ],\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"name\": \"OUTPUT0\",\n",
      "            \"data_type\": \"TYPE_FP32\",\n",
      "            \"dims\": [\n",
      "                -1\n",
      "            ],\n",
      "            \"label_filename\": \"\",\n",
      "            \"is_shape_tensor\": false\n",
      "        }\n",
      "    ],\n",
      "    \"batch_input\": [],\n",
      "    \"batch_output\": [],\n",
      "    \"optimization\": {\n",
      "        \"priority\": \"PRIORITY_DEFAULT\",\n",
      "        \"input_pinned_memory\": {\n",
      "            \"enable\": true\n",
      "        },\n",
      "        \"output_pinned_memory\": {\n",
      "            \"enable\": true\n",
      "        },\n",
      "        \"gather_kernel_buffer_threshold\": 0,\n",
      "        \"eager_batching\": false\n",
      "    },\n",
      "    \"instance_group\": [\n",
      "        {\n",
      "            \"name\": \"wdl_0\",\n",
      "            \"kind\": \"KIND_GPU\",\n",
      "            \"count\": 1,\n",
      "            \"gpus\": [\n",
      "                2\n",
      "            ],\n",
      "            \"profile\": []\n",
      "        }\n",
      "    ],\n",
      "    \"default_model_filename\": \"\",\n",
      "    \"cc_model_filenames\": {},\n",
      "    \"metric_tags\": {},\n",
      "    \"parameters\": {\n",
      "        \"des_feature_num\": {\n",
      "            \"string_value\": \"13\"\n",
      "        },\n",
      "        \"embeddingkey_long_type\": {\n",
      "            \"string_value\": \"true\"\n",
      "        },\n",
      "        \"gpucache\": {\n",
      "            \"string_value\": \"true\"\n",
      "        },\n",
      "        \"hit_rate_threshold\": {\n",
      "            \"string_value\": \"0.8\"\n",
      "        },\n",
      "        \"slots\": {\n",
      "            \"string_value\": \"28\"\n",
      "        },\n",
      "        \"cat_feature_num\": {\n",
      "            \"string_value\": \"28\"\n",
      "        },\n",
      "        \"config\": {\n",
      "            \"string_value\": \"/wdl_infer/model/wdl/1/wdl.json\"\n",
      "        },\n",
      "        \"label_dim\": {\n",
      "            \"string_value\": \"1\"\n",
      "        },\n",
      "        \"max_nnz\": {\n",
      "            \"string_value\": \"2\"\n",
      "        },\n",
      "        \"gpucacheper\": {\n",
      "            \"string_value\": \"0.5\"\n",
      "        },\n",
      "        \"embedding_vector_size\": {\n",
      "            \"string_value\": \"128\"\n",
      "        }\n",
      "    },\n",
      "    \"model_warmup\": []\n",
      "}\n",
      "I0914 10:46:05.870782 2543 hugectr.cc:652] The model configuration:\n",
      "{\n",
      "    \"name\": \"wdl\",\n",
      "    \"platform\": \"\",\n",
      "    \"backend\": \"hugectr\",\n",
      "    \"version_policy\": {\n",
      "        \"latest\": {\n",
      "            \"num_versions\": 1\n",
      "        }\n",
      "    },\n",
      "    \"max_batch_size\": 64,\n",
      "    \"input\": [\n",
      "        {\n",
      "            \"name\": \"DES\",\n",
      "            \"data_type\": \"TYPE_FP32\",\n",
      "            \"format\": \"FORMAT_NONE\",\n",
      "            \"dims\": [\n",
      "                -1\n",
      "            ],\n",
      "            \"is_shape_tensor\": false,\n",
      "            \"allow_ragged_batch\": false\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"CATCOLUMN\",\n",
      "            \"data_type\": \"TYPE_INT64\",\n",
      "            \"format\": \"FORMAT_NONE\",\n",
      "            \"dims\": [\n",
      "                -1\n",
      "            ],\n",
      "            \"is_shape_tensor\": false,\n",
      "            \"allow_ragged_batch\": false\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"ROWINDEX\",\n",
      "            \"data_type\": \"TYPE_INT32\",\n",
      "            \"format\": \"FORMAT_NONE\",\n",
      "            \"dims\": [\n",
      "                -1\n",
      "            ],\n",
      "            \"is_shape_tensor\": false,\n",
      "            \"allow_ragged_batch\": false\n",
      "        }\n",
      "    ],\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"name\": \"OUTPUT0\",\n",
      "            \"data_type\": \"TYPE_FP32\",\n",
      "            \"dims\": [\n",
      "                -1\n",
      "            ],\n",
      "            \"label_filename\": \"\",\n",
      "            \"is_shape_tensor\": false\n",
      "        }\n",
      "    ],\n",
      "    \"batch_input\": [],\n",
      "    \"batch_output\": [],\n",
      "    \"optimization\": {\n",
      "        \"priority\": \"PRIORITY_DEFAULT\",\n",
      "        \"input_pinned_memory\": {\n",
      "            \"enable\": true\n",
      "        },\n",
      "        \"output_pinned_memory\": {\n",
      "            \"enable\": true\n",
      "        },\n",
      "        \"gather_kernel_buffer_threshold\": 0,\n",
      "        \"eager_batching\": false\n",
      "    },\n",
      "    \"instance_group\": [\n",
      "        {\n",
      "            \"name\": \"wdl_0\",\n",
      "            \"kind\": \"KIND_GPU\",\n",
      "            \"count\": 1,\n",
      "            \"gpus\": [\n",
      "                2\n",
      "            ],\n",
      "            \"profile\": []\n",
      "        }\n",
      "    ],\n",
      "    \"default_model_filename\": \"\",\n",
      "    \"cc_model_filenames\": {},\n",
      "    \"metric_tags\": {},\n",
      "    \"parameters\": {\n",
      "        \"des_feature_num\": {\n",
      "            \"string_value\": \"13\"\n",
      "        },\n",
      "        \"embeddingkey_long_type\": {\n",
      "            \"string_value\": \"true\"\n",
      "        },\n",
      "        \"gpucache\": {\n",
      "            \"string_value\": \"true\"\n",
      "        },\n",
      "        \"hit_rate_threshold\": {\n",
      "            \"string_value\": \"0.8\"\n",
      "        },\n",
      "        \"slots\": {\n",
      "            \"string_value\": \"28\"\n",
      "        },\n",
      "        \"cat_feature_num\": {\n",
      "            \"string_value\": \"28\"\n",
      "        },\n",
      "        \"config\": {\n",
      "            \"string_value\": \"/wdl_infer/model/wdl/1/wdl.json\"\n",
      "        },\n",
      "        \"label_dim\": {\n",
      "            \"string_value\": \"1\"\n",
      "        },\n",
      "        \"max_nnz\": {\n",
      "            \"string_value\": \"2\"\n",
      "        },\n",
      "        \"gpucacheper\": {\n",
      "            \"string_value\": \"0.5\"\n",
      "        },\n",
      "        \"embedding_vector_size\": {\n",
      "            \"string_value\": \"128\"\n",
      "        }\n",
      "    },\n",
      "    \"model_warmup\": []\n",
      "}\n",
      "I0914 10:46:05.871003 2543 hugectr.cc:689] slots set is : 28\n",
      "I0914 10:46:05.871019 2543 hugectr.cc:697] desene number is : 13\n",
      "I0914 10:46:05.871031 2543 hugectr.cc:706] cat_feature number is : 28\n",
      "I0914 10:46:05.871043 2543 hugectr.cc:719] embedding size is  128\n",
      "I0914 10:46:05.871055 2543 hugectr.cc:727] maxnnz is 2\n",
      "I0914 10:46:05.871066 2543 hugectr.cc:734] Hugectr model config path is /wdl_infer/model/wdl/1/wdl.json\n",
      "I0914 10:46:05.871078 2543 hugectr.cc:744] support gpu cache is 1\n",
      "I0914 10:46:05.871096 2543 hugectr.cc:752] gpu cache per is 0.500000\n",
      "I0914 10:46:05.871108 2543 hugectr.cc:761] gpu cache per is 0.500000\n",
      "I0914 10:46:05.871119 2543 hugectr.cc:769] Label dim is 1\n",
      "I0914 10:46:05.871131 2543 hugectr.cc:781] Support long long embedding key is 1\n",
      "I0914 10:46:05.871143 2543 hugectr.cc:786] max_batch_size is 64\n",
      "I0914 10:46:05.871155 2543 hugectr.cc:797] ******Creating Embedding Cache for model wdl in device 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0914 10:46:05.925549 2543 hugectr.cc:817] ******Creating Embedding Cache for model wdl successfully\n",
      "I0914 10:46:05.925885 2543 hugectr.cc:1242] TRITONBACKEND_ModelInstanceInitialize: wdl_0 (device 2)\n",
      "I0914 10:46:05.925903 2543 hugectr.cc:932] Triton Model Instance Initialization on device 2\n",
      "I0914 10:46:05.925916 2543 hugectr.cc:943] Dense Feature buffer allocation: \n",
      "I0914 10:46:06.528513 2543 hugectr.cc:949] Categorical Feature buffer allocation: \n",
      "I0914 10:46:06.645175 2543 hugectr.cc:964] Categorical Row Index buffer allocation: \n",
      "I0914 10:46:06.645260 2543 hugectr.cc:970] Predict result buffer allocation: \n",
      "I0914 10:46:06.645307 2543 hugectr.cc:1265] ******Loading HugeCTR Model***** \n",
      "I0914 10:46:06.645327 2543 hugectr.cc:988] The model origin json configuration file path is: /wdl_infer/model/wdl/1/wdl.json\n",
      "[14d10h46m06s][HUGECTR][INFO]: Global seed is 1088844895\n",
      "[14d10h46m06s][HUGECTR][INFO]: Device to NUMA mapping:\n",
      "  GPU 2 ->  node 1\n",
      "\n",
      "[14d10h46m22s][HUGECTR][INFO]: Peer-to-peer access cannot be fully enabled.\n",
      "[14d10h46m22s][HUGECTR][INFO]: Start all2all warmup\n",
      "[14d10h46m22s][HUGECTR][INFO]: End all2all warmup\n",
      "[14d10h46m22s][HUGECTR][INFO]: Use mixed precision: 0\n",
      "[14d10h46m22s][HUGECTR][INFO]: start create embedding for inference\n",
      "[14d10h46m22s][HUGECTR][INFO]: sparse_input name wide_data\n",
      "[14d10h46m22s][HUGECTR][INFO]: sparse_input name deep_data\n",
      "[14d10h46m22s][HUGECTR][INFO]: create embedding for inference success\n",
      "[14d10h46m22s][HUGECTR][INFO]: Inference stage skip BinaryCrossEntropyLoss layer, replaced by Sigmoid layer\n",
      "I0914 10:46:22.688742 2543 hugectr.cc:991] ******Loading HugeCTR model successfully\n",
      "I0914 10:46:22.689235 2543 model_repository_manager.cc:1240] successfully loaded 'wdl' version 1\n",
      "I0914 10:46:22.689462 2543 server.cc:504] \n",
      "+------------------+------+\n",
      "| Repository Agent | Path |\n",
      "+------------------+------+\n",
      "+------------------+------+\n",
      "\n",
      "I0914 10:46:22.689616 2543 server.cc:543] \n",
      "+----------+--------------------------------+--------------------------------+\n",
      "| Backend  | Path                           | Config                         |\n",
      "+----------+--------------------------------+--------------------------------+\n",
      "| tensorrt | <built-in>                     | {}                             |\n",
      "| hugectr  | /usr/local/hugectr/backends/hu | {\"cmdline\":{\"ps\":\"/wdl_infer/m |\n",
      "|          | gectr/libtriton_hugectr.so     | odel/ps.json\"}}                |\n",
      "+----------+--------------------------------+--------------------------------+\n",
      "\n",
      "I0914 10:46:22.689739 2543 server.cc:586] \n",
      "+-------+---------+--------+\n",
      "| Model | Version | Status |\n",
      "+-------+---------+--------+\n",
      "| wdl   | 1       | READY  |\n",
      "+-------+---------+--------+\n",
      "\n",
      "I0914 10:46:22.690013 2543 tritonserver.cc:1658] \n",
      "+----------------------------------+------------------------------------------+\n",
      "| Option                           | Value                                    |\n",
      "+----------------------------------+------------------------------------------+\n",
      "| server_id                        | triton                                   |\n",
      "| server_version                   | 2.9.0                                    |\n",
      "| server_extensions                | classification sequence model_repository |\n",
      "|                                  |  model_repository(unload_dependents) sch |\n",
      "|                                  | edule_policy model_configuration system_ |\n",
      "|                                  | shared_memory cuda_shared_memory binary_ |\n",
      "|                                  | tensor_data statistics                   |\n",
      "| model_repository_path[0]         | /wdl_infer/model/                        |\n",
      "| model_control_mode               | MODE_EXPLICIT                            |\n",
      "| startup_models_0                 | wdl                                      |\n",
      "| strict_model_config              | 1                                        |\n",
      "| pinned_memory_pool_byte_size     | 268435456                                |\n",
      "| cuda_memory_pool_byte_size{0}    | 67108864                                 |\n",
      "| cuda_memory_pool_byte_size{1}    | 67108864                                 |\n",
      "| cuda_memory_pool_byte_size{2}    | 67108864                                 |\n",
      "| cuda_memory_pool_byte_size{3}    | 67108864                                 |\n",
      "| min_supported_compute_capability | 6.0                                      |\n",
      "| strict_readiness                 | 1                                        |\n",
      "| exit_timeout                     | 30                                       |\n",
      "+----------------------------------+------------------------------------------+\n",
      "\n",
      "I0914 10:46:22.753740 2543 grpc_server.cc:4028] Started GRPCInferenceService at 0.0.0.0:8001\n",
      "I0914 10:46:22.787886 2543 http_server.cc:2761] Started HTTPService at 0.0.0.0:8000\n",
      "I0914 10:46:22.831173 2543 http_server.cc:2780] Started Metrics Service at 0.0.0.0:8002\n",
      "^C\n",
      "Signal (2) received.\n",
      "I0914 10:47:48.839754 2543 server.cc:234] Waiting for in-flight requests to complete.\n",
      "I0914 10:47:48.839796 2543 model_repository_manager.cc:1099] unloading: wdl:1\n",
      "I0914 10:47:48.840009 2543 server.cc:249] Timeout 30: Found 1 live models and 0 in-flight non-inference requests\n",
      "I0914 10:47:48.840188 2543 hugectr.cc:1282] TRITONBACKEND_ModelInstanceFinalize: delete instance state\n"
     ]
    }
   ],
   "source": [
    "!tritonserver --model-repository=/wdl_infer/model/ --load-model=wdl \\\n",
    "    --model-control-mode=explicit \\\n",
    "    --backend-directory=/usr/local/hugectr/backends \\\n",
    "    --backend-config=hugectr,ps=/wdl_infer/model/ps.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Check Triton server status if deploy Wide&Deep model successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\r\n",
      "*   Trying 127.0.0.1:8000...\r\n",
      "* Connected to localhost (127.0.0.1) port 8000 (#0)\r\n",
      "> GET /v2/health/ready HTTP/1.1\r\n",
      "\r\n",
      "> Host: localhost:8000\r\n",
      "\r\n",
      "> User-Agent: curl/7.68.0\r\n",
      "\r\n",
      "> Accept: */*\r\n",
      "\r\n",
      "> \r\n",
      "\r\n",
      "* Mark bundle as not supporting multiuse\r\n",
      "< HTTP/1.1 200 OK\r\n",
      "\r\n",
      "< Content-Length: 0\r\n",
      "\r\n",
      "< Content-Type: text/plain\r\n",
      "\r\n",
      "< \r\n",
      "\r\n",
      "* Connection #0 to host localhost left intact\r\n"
     ]
    }
   ],
   "source": [
    "!curl -v localhost:8000/v2/health/ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Prepare Inference Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Read validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 637376\r\n",
      "-rw-r--r-- 1 root root 142856977 Jul  5 05:44 0.110d099942694a5cbf1b71eb73e10f27.parquet\r\n",
      "-rw-r--r-- 1 root root        51 Jul  6 07:02 _file_list.txt\r\n",
      "-rw-r--r-- 1 root root     27701 Jul  5 05:44 _metadata\r\n",
      "-rw-r--r-- 1 root root      1537 Jul  5 05:44 _metadata.json\r\n",
      "drwxr-xr-x 2 root root      4096 Jul  5 05:42 temp-parquet-after-conversion\r\n",
      "-rw-r--r-- 1 1025 1025 509766965 Jul  5 04:45 test.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l /wdl_train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"/wdl_train/val/0.110d099942694a5cbf1b71eb73e10f27.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.061161</td>\n",
       "      <td>0.974006</td>\n",
       "      <td>-0.594327</td>\n",
       "      <td>-0.157301</td>\n",
       "      <td>-0.224758</td>\n",
       "      <td>0.618222</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.281810</td>\n",
       "      <td>-0.760031</td>\n",
       "      <td>1.386036</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>666</td>\n",
       "      <td>1</td>\n",
       "      <td>33722</td>\n",
       "      <td>24373</td>\n",
       "      <td>91481</td>\n",
       "      <td>62242</td>\n",
       "      <td>7673</td>\n",
       "      <td>44</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.061206</td>\n",
       "      <td>-0.437431</td>\n",
       "      <td>0.156849</td>\n",
       "      <td>-0.146861</td>\n",
       "      <td>-0.193763</td>\n",
       "      <td>0.893091</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>0.286841</td>\n",
       "      <td>-0.109336</td>\n",
       "      <td>3.242455</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>666</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>97438</td>\n",
       "      <td>0</td>\n",
       "      <td>21446</td>\n",
       "      <td>4472</td>\n",
       "      <td>56</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.043427</td>\n",
       "      <td>-0.464600</td>\n",
       "      <td>-0.379705</td>\n",
       "      <td>-0.120014</td>\n",
       "      <td>0.054203</td>\n",
       "      <td>-0.206385</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.093999</td>\n",
       "      <td>-0.543133</td>\n",
       "      <td>-0.470383</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>575</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>46601</td>\n",
       "      <td>0</td>\n",
       "      <td>12090</td>\n",
       "      <td>540</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.059432</td>\n",
       "      <td>-0.273058</td>\n",
       "      <td>-0.487016</td>\n",
       "      <td>-0.143878</td>\n",
       "      <td>-0.193763</td>\n",
       "      <td>-0.206385</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.279201</td>\n",
       "      <td>-0.109336</td>\n",
       "      <td>-0.470383</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>351</td>\n",
       "      <td>10</td>\n",
       "      <td>125237</td>\n",
       "      <td>4329</td>\n",
       "      <td>238309</td>\n",
       "      <td>0</td>\n",
       "      <td>8488</td>\n",
       "      <td>56</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.048792</td>\n",
       "      <td>-0.418412</td>\n",
       "      <td>0.693403</td>\n",
       "      <td>0.300589</td>\n",
       "      <td>-0.193763</td>\n",
       "      <td>-0.206385</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.281810</td>\n",
       "      <td>0.902856</td>\n",
       "      <td>-0.470383</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>575</td>\n",
       "      <td>7</td>\n",
       "      <td>69747</td>\n",
       "      <td>76381</td>\n",
       "      <td>207280</td>\n",
       "      <td>0</td>\n",
       "      <td>444</td>\n",
       "      <td>73</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         I1        I2        I3        I4        I5        I6        I7  \\\n",
       "0  0.061161  0.974006 -0.594327 -0.157301 -0.224758  0.618222 -0.064249   \n",
       "1 -0.061206 -0.437431  0.156849 -0.146861 -0.193763  0.893091 -0.064249   \n",
       "2  0.043427 -0.464600 -0.379705 -0.120014  0.054203 -0.206385 -0.064249   \n",
       "3 -0.059432 -0.273058 -0.487016 -0.143878 -0.193763 -0.206385 -0.064249   \n",
       "4 -0.048792 -0.418412  0.693403  0.300589 -0.193763 -0.206385 -0.064249   \n",
       "\n",
       "         I8        I9       I10  ...  C17  C18  C19     C20    C21     C22  \\\n",
       "0 -0.281810 -0.760031  1.386036  ...    2  666    1   33722  24373   91481   \n",
       "1  0.286841 -0.109336  3.242455  ...    1  666   10       0  97438       0   \n",
       "2 -0.093999 -0.543133 -0.470383  ...    1  575   10       0  46601       0   \n",
       "3 -0.279201 -0.109336 -0.470383  ...    0  351   10  125237   4329  238309   \n",
       "4 -0.281810  0.902856 -0.470383  ...    0  575    7   69747  76381  207280   \n",
       "\n",
       "     C23   C24  C25  C26  \n",
       "0  62242  7673   44   28  \n",
       "1  21446  4472   56   19  \n",
       "2  12090   540   10   17  \n",
       "3      0  8488   56   22  \n",
       "4      0   444   73   22  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10).to_csv('/wdl_infer/infer_test.txt', sep='\\t', index=False,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Follow the Triton requirements to generate inference requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /wdl_infer/wdl2predict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '/wdl_infer/wdl2predict.py'\n",
    "from tritonclient.utils import *\n",
    "import tritonclient.http  as httpclient\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "model_name = 'wdl'\n",
    "CATEGORICAL_COLUMNS=[\"C\" + str(x) for x in range(1, 27)]+[\"C1_C2\",\"C3_C4\"]\n",
    "CONTINUOUS_COLUMNS=[\"I\" + str(x) for x in range(1, 14)]\n",
    "LABEL_COLUMNS = ['label']\n",
    "emb_size_array = [249058, 19561, 14212, 6890, 18592, 4, 6356, 1254, 52, 226170, 80508, 72308, 11, 2169, 7597, 61, 4, 923, 15, 249619, 168974, 243480, 68212, 9169, 75, 34, 278018, 415262]\n",
    "shift = np.insert(np.cumsum(emb_size_array), 0, 0)[:-1]\n",
    "test_df=pd.read_csv(\"/wdl_infer/infer_test.txt\",sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "with httpclient.InferenceServerClient(\"localhost:8000\") as client:\n",
    "    dense_features = np.array([list(test_df[CONTINUOUS_COLUMNS].values.flatten())],dtype='float32')\n",
    "    embedding_columns = np.array([list((test_df[CATEGORICAL_COLUMNS]+shift).values.flatten())],dtype='int64')\n",
    "    row_ptrs = np.array([list(range(0,21))+list(range(0,261))],dtype='int32')\n",
    "    \n",
    "    inputs = [\n",
    "        httpclient.InferInput(\"DES\", dense_features.shape,\n",
    "                              np_to_triton_dtype(dense_features.dtype)),\n",
    "        httpclient.InferInput(\"CATCOLUMN\", embedding_columns.shape,\n",
    "                              np_to_triton_dtype(embedding_columns.dtype)),\n",
    "        httpclient.InferInput(\"ROWINDEX\", row_ptrs.shape,\n",
    "                              np_to_triton_dtype(row_ptrs.dtype)),\n",
    "\n",
    "    ]\n",
    "\n",
    "    inputs[0].set_data_from_numpy(dense_features)\n",
    "    inputs[1].set_data_from_numpy(embedding_columns)\n",
    "    inputs[2].set_data_from_numpy(row_ptrs)\n",
    "    outputs = [\n",
    "        httpclient.InferRequestedOutput(\"OUTPUT0\")\n",
    "    ]\n",
    "\n",
    "    response = client.infer(model_name,\n",
    "                            inputs,\n",
    "                            request_id=str(1),\n",
    "                            outputs=outputs)\n",
    "\n",
    "    result = response.get_response()\n",
    "    print(result)\n",
    "    print(\"Prediction Result:\")\n",
    "    print(response.as_numpy(\"OUTPUT0\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Send requests to Triton Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '1', 'model_name': 'wdl', 'model_version': '1', 'parameters': {'NumSample': 10, 'DeviceID': 2}, 'outputs': [{'name': 'OUTPUT0', 'datatype': 'FP32', 'shape': [10], 'parameters': {'binary_data_size': 40}}]}\r\n",
      "Prediction Result:\r\n",
      "[0.01995986 0.02527472 0.01790315 0.00693272 0.0233907  0.0227473\r\n",
      " 0.05989734 0.01598154 0.00582242 0.01423134]\r\n"
     ]
    }
   ],
   "source": [
    "!python3 /wdl_infer/wdl2predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
