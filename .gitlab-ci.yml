include:
  - project: 'dl/devops/gitlab-ci-slurm'
    ref: master
    file: '/.gitlab-ci.yml'

stages:
  - build
  - test

variables:
  IMAGE_LATEST: "${CI_REGISTRY}/dl/hugectr/hugectr_inference_backend:${CI_COMMIT_BRANCH}.latest"
  IMAGE_VERSIONED: "${CI_REGISTRY}/dl/hugectr/hugectr_inference_backend:${CI_COMMIT_BRANCH}.${CI_PIPELINE_ID}"

.cluster_test_job:
  extends: .dlcluster_job
  variables:
    CI_SLURM_PARTITION: "a100-pcie-40gb-product,a100-pcie-80gb-product"
    CI_SLURM_ACCOUNT: "cag"
    CI_SCHEDULER_TYPE: docker
    GPUS_PER_NODE: "--gres=gpu:4"
    WALLTIME:      "02:00:00"
  tags:
  - computelab_generic
  allow_failure: false
  stage: test
  dependencies: 
    - build
  # only:
  #   - merge_requests
  #   - web
  
### Stage: build
build:
  tags:
    - 1GPU
  stage: build
  script:
    - docker login -u ${CI_PRIVATE_USER} -p "${CI_PRIVATE_KEY}" "${CI_REGISTRY}"
    - export JOB_DOCKERFILE="Dockerfile.${CI_JOB_NAME%%--*}.${CI_PIPELINE_ID}" && echo ${JOB_DOCKERFILE}
    - cat ./test/CI.DockerFile > ${JOB_DOCKERFILE}
    - sed -i "s/https\:\/\/github.com\/NVIDIA\/HugeCTR.git/https:\/\/gitlab-ci-token:${CI_JOB_TOKEN}@gitlab-master.nvidia.com\/dl\/hugectr\/hugectr.git/g" ${JOB_DOCKERFILE}
    - sed -i "s/https:\/\/gitlab-master.nvidia.com\/dl\/hugectr\/hugectr_inference_backend.git/https:\/\/gitlab-ci-token:${CI_JOB_TOKEN}@gitlab-master.nvidia.com\/dl\/hugectr\/hugectr_inference_backend.git/g" ${JOB_DOCKERFILE}
    - sed -i "s/HUGECTR_BRANCH=main/HUGECTR_BRANCH=master/g" ${JOB_DOCKERFILE}
    - sed -i "s/INFERENCE_BRANCH=main/INFERENCE_BRANCH=${CI_COMMIT_BRANCH}/g" ${JOB_DOCKERFILE}
    - cat ${JOB_DOCKERFILE}
    - docker build --pull
        -t "${IMAGE_VERSIONED}"
        -f ${JOB_DOCKERFILE}
        ${PWD}
    - docker push "${IMAGE_VERSIONED}"
    - docker tag ${IMAGE_VERSIONED} ${IMAGE_LATEST}
    - docker push ${IMAGE_LATEST}
  # only:
  #   - pushes
  #   - merge_requests
  #   - web

dlrm_test:
  extends: .cluster_test_job
  script:
    - export IMAGE_LATEST_CORRECTE=$(echo $IMAGE_VERSIONED | sed 's/https:\/\///g')
    - bash -cx "
      echo $(pwd);
      nvidia-smi;
      cd ./test;
      docker login -u ${CI_PRIVATE_USER} -p "${CI_PRIVATE_KEY}" "${CI_REGISTRY}";
      bash ./triton_server.sh ${IMAGE_LATEST_CORRECTE} /home/scratch.svc_compute_arch/hugectr-ci/inference_ci/model_repository dlrm;
      docker run --rm --net=host -v /home/scratch.svc_compute_arch/hugectr-ci/inference_ci/inference_demo:/demo gitlab-master.nvidia.com:5005/dl/hugectr/hugectr:devel_all perf_analyzer -m dlrm -u localhost:8000 --input-data /demo/1.json --shape CATCOLUMN:26 --shape DES:13 --shape ROWINDEX:27;
      docker run --rm --net=host -v /home/scratch.svc_compute_arch/hugectr-ci/inference_ci/inference_demo:/demo gitlab-master.nvidia.com:5005/dl/hugectr/hugectr:devel_all python3 /demo/dlrm.py;
      docker run --rm --net=host -v /home/scratch.svc_compute_arch/hugectr-ci/inference_ci/inference_demo:/demo gitlab-master.nvidia.com:5005/dl/hugectr/hugectr:devel_all python3 /demo/dlrm_test.py;
      "

wdl_test:
  extends: .cluster_test_job
  variables:
    CI_SLURM_PARTITION: "tesla-v100-sxm2-16gb-product,tesla-v100-sxm3-32gb-product"
  script:
    - export IMAGE_LATEST_CORRECTE=$(echo $IMAGE_VERSIONED | sed 's/https:\/\///g')
    - bash -cx "
      echo $(pwd);
      nvidia-smi;
      cd ./test;
      docker login -u ${CI_PRIVATE_USER} -p "${CI_PRIVATE_KEY}" "${CI_REGISTRY}";
      bash ./triton_server.sh ${IMAGE_LATEST_CORRECTE} /home/scratch.svc_compute_arch/hugectr-ci/inference_ci/model_repository wdl;
      docker run --rm --net=host -v /home/scratch.svc_compute_arch/hugectr-ci/inference_ci/inference_demo:/demo gitlab-master.nvidia.com:5005/dl/hugectr/hugectr:devel_all python3 /demo/wdl2predict.py;
      "
